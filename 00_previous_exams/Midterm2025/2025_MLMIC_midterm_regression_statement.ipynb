{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dc77de0",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING                                                  \n",
    "\n",
    "# Midterm exam 2025\n",
    "\n",
    "<h1 style=\"color:red;\">Instructions: Read Carefully!</h1>\n",
    "\n",
    "\n",
    "- **[Use this Jupyter notebook]{.underline}** to complete the required tasks and submit it to Moodle. Keep the sectioning structure of the notebook and insert the code cells you need in the corresponding sections.\n",
    "\n",
    "- The notebook should contain the code with your **analysis** and **it must be reproducible**. Set the random seeds to ensure that.\n",
    "\n",
    "- The **most important part of your work is the comments and interpretation** of the analysis results obtained. **Do not include uncommented figures**. Remember to include a **conclusion section** at the end.                          \n",
    "\n",
    "- **[Use OBS to record your screen]{.underline}**. Upload the video file (max. 500Mb) to Moodle. Alternatively, make sure to copy it to one of the pendrives that will be provided.\n",
    "\n",
    "- The exam has **two notebooks:** one for the Classification problem (30% of the grading) and this one for the **Regression Problem**. You must submit both of them to Moodle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f1a49",
   "metadata": {},
   "source": [
    "## Statement of the Regression Problem\n",
    "\n",
    "### Dataset \n",
    "\n",
    "+ Look for your student code in the `student_codes.txt` file. Use the corresponding zip file cpntaining the data files for your analysis.  \n",
    "  **IMPORTANT:** An exam done with a wrong dataset implies a failed exam.                        \n",
    "\n",
    "+ Load the training set **dfTR_reg_XX.csv** and the test set **dfTS_reg_XX.csv** corresponding to your student code.\n",
    "\n",
    "+ The dataset contains 7 input variables called X1 to X7. The output numeric variable is called Y.\n",
    "\n",
    "### External Code and Imports\n",
    "\n",
    "+ The first code cell below contains standard imports that we have used in the sessions. With these imports you should be able to do all the tasks in the exam; that is not to say that you need to use all of them, and you are invited to use extra imports if you feel the need.\n",
    "\n",
    "+ We have also included a Python script `auxiliary_code.py` with two functions called `ResidualPlots` and `explore_outliers` that will be available when you run the second cell in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0190b2ac",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red;\">The regression problem has two parts, using the same dataset.</h2>\n",
    "\n",
    "We **strongly recommend** you to organize your work using the results in the sessions of the course corresponding to the model you are fitting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb5361c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png' # ‘png’, ‘retina’, ‘jpeg’, ‘svg’, ‘pdf’\n",
    "\n",
    "# plotting libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data management libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Connecting statsmodels with sklearn via sklearn2pmml and patsy \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "from sklearn2pmml.statsmodels import StatsModelsRegressor\n",
    "import patsy as ps\n",
    "\n",
    "from patsy_utils.patsy_formulaic_transformer import FormulaTransformer\n",
    "# Scikit transformers and pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, PowerTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Scikit metrics and model selection\n",
    "from sklearn.metrics import root_mean_squared_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "\n",
    "# Scikit-learn regression models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec1857",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i \"auxiliary_code.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e64df58",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Regression Part I</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d676b85e",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;\">**IMPORTANT:** </span>\n",
    "+ <span style=\"color:blue;\">We have provided you with separate training and test sets for reproducibility. But **the training set may still need preprocessing!** Do not assume that the training data has been thoroughly cleaned. The test set, on the other hand, can be used as it is.\n",
    "</span>\n",
    "+ <span style=\"color:blue;\">Use RMSE as the evaluation metric for this part of the exam.</span>\n",
    "\n",
    "### 1.1  Exploratory analysis of the training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad38873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your student code to select the data files.\n",
    "dfTR = pd.read_csv(\"./dataRegression/dfTR_reg_XX.csv\")\n",
    "dfTS = pd.read_csv(\"./dataRegression/dfTS_reg_XX.csv\")\n",
    "dfTR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e44131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7908c81",
   "metadata": {},
   "source": [
    "### 1.2. Fit a linear regression model to the training set\n",
    "\n",
    "+ **Fit an initial linear regression model to the training set to predict the output variable Y using (possibly a subset of) X1, ..., X7 as input variables.**\n",
    "+ **This is a first and exploratory linear model. Keep it simple.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1e2f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd4b6891",
   "metadata": {},
   "source": [
    "#### 1.2.1. Analyze the significance of the model coefficients and the residuals plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab20ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88171883",
   "metadata": {},
   "source": [
    "#### 1.2.2. Scores for this model\n",
    "\n",
    "+ **Obtain the training, test and validation scores for this model.**\n",
    "+ **Store them in a model dictionary like we have done in the course sessions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4f9995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b062146d",
   "metadata": {},
   "source": [
    "### 1.3 Second Linear Model\n",
    "\n",
    "+ **Using the findings in 1.2 fit a second linear model to see if you can improve its performance.**\n",
    "+ **Again, for this second model, analyze the significance of the coefficients, the residual plots and store the train, test and validation scores in the model dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525823b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2828194",
   "metadata": {},
   "source": [
    "### 1.4 Lasso (Optional) \n",
    "\n",
    "+ **Only if you have time, after addressing the part below**\n",
    "+ **Fit a Lasso model to the data. Use grid search to find the best alpha parameter.**\n",
    "+ **What variables are selected by this model?**\n",
    "+ **Analyze the residual plots and store the train, test and validation scores in the model dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e2d6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "460f62c4",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Regression Part II</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0398f",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;\">**IMPORTANT:** </span>\n",
    "+ <span style=\"color:blue;\">We **strongly recommend** you to organize your work using the results in the corresponding session of the course.</span> \n",
    "+ <span style=\"color:blue;\">In particular we recommend that you start with a fresh version of the data sets, by reloading them. </span>\n",
    "+ <span style=\"color:blue;\">To speed up your work keep in mind that this is the same dataset, so you should already have gone through EDA. Do not repeat the same EDA analysis, use it!</span>\n",
    "+ <span style=\"color:blue;\">But we also advise you to **keep the model dictionary** of the first part and add the models in this part to it for easy model comparison.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec60539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your student code to select the data files.\n",
    "dfTR = pd.read_csv(\"./dataRegression/dfTR_reg_XX.csv\")\n",
    "dfTS = pd.read_csv(\"./dataRegression/dfTS_reg_XX.csv\")\n",
    "dfTR.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b31528a",
   "metadata": {},
   "source": [
    "### 1.5. Histogram Gradient Boosting regression\n",
    "\n",
    "#### 1.5.1. Fit a histogram gradient boosting regression model for the training dataset. \n",
    "\n",
    "+ **Use grid search to select the hyperparameters of the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1871c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8f7f065",
   "metadata": {},
   "source": [
    "#### 1.5.2. Scores for this model\n",
    "\n",
    "+ **Obtain the training, test and validation scores for this model.**\n",
    "+ **Store them in a model dictionary like we have done in the course sessions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da620e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bb63e6d",
   "metadata": {},
   "source": [
    "### 1.6 Model Comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9829d957",
   "metadata": {},
   "source": [
    "#### 1.6.1 Compare all the models in the model dictionary using the training, test and validation scores. \n",
    "\n",
    "+ **Remember to use RMSE scores for this comparison.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77633f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3248294",
   "metadata": {},
   "source": [
    "#### 1.6.2 Which model would you choose? Why?\n",
    "\n",
    "+ **State your conclusions for the regression part.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81559703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25c5004d",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;\">Ok</h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLMIC25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
